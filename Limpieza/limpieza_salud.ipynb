{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e866a8e1",
   "metadata": {},
   "source": [
    "### Vizualizaciónes iniciales; \n",
    "pd: bueno aqui voy a tomar los datos y ver que ondita: Solo tome primer semestre 2025, hay muchos más periodos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66f3d6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "307ac873",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rn/8kg7t05x7l3fy1mwbgcdkw240000gp/T/ipykernel_35655/2135878628.py:3: DtypeWarning: Columns (10,11,12,17,28,50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_cm = pd.read_csv('data/salud/sa2025/07OCConvenioMarco.csv', delimiter=';', encoding='latin-1')\n",
      "/var/folders/rn/8kg7t05x7l3fy1mwbgcdkw240000gp/T/ipykernel_35655/2135878628.py:4: DtypeWarning: Columns (11,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_lic = pd.read_csv('data/salud/sa2025/07OCLicitacion.csv', delimiter=';', encoding='latin-1')\n",
      "/var/folders/rn/8kg7t05x7l3fy1mwbgcdkw240000gp/T/ipykernel_35655/2135878628.py:5: DtypeWarning: Columns (7,8,13,35,38,42,43,49,57,58,59,61) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_ca = pd.read_csv('data/salud/sa2025/07OCCompraAgil.csv', delimiter=';', encoding='latin-1')\n"
     ]
    }
   ],
   "source": [
    "# Cargar directamente con latin-1 (sino problemas de codificacion -\\./-)\n",
    "df_td = pd.read_csv('data/salud/sa2025/07OCTratoDirecto.csv', delimiter=';', encoding='latin-1')\n",
    "df_cm = pd.read_csv('data/salud/sa2025/07OCConvenioMarco.csv', delimiter=';', encoding='latin-1')\n",
    "df_lic = pd.read_csv('data/salud/sa2025/07OCLicitacion.csv', delimiter=';', encoding='latin-1')\n",
    "df_ca = pd.read_csv('data/salud/sa2025/07OCCompraAgil.csv', delimiter=';', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45c17652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limpiando datos del sector salud...\n",
      "\n",
      "==================================================\n",
      "RESULTADOS DE LA LIMPIEZA\n",
      "==================================================\n",
      "\n",
      "Trato Directo:\n",
      "  • Registros: 11,788\n",
      "  • Columnas: 50\n",
      "  • Monto total: $185,054,146,866 CLP\n",
      "  • Monto promedio: $15,698,519 CLP\n",
      "  • Valores nulos en MontoTotalOC: 0\n",
      "  • Fechas nulas: 0\n",
      "  • Rango de fechas: 2025-01-02 00:00:00 a 2025-03-31 00:00:00\n",
      "\n",
      "Convenio Marco:\n",
      "  • Registros: 49,682\n",
      "  • Columnas: 65\n",
      "  • Monto total: $250,419,969,582 CLP\n",
      "  • Monto promedio: $5,040,457 CLP\n",
      "  • Valores nulos en MontoTotalOC: 0\n",
      "  • Fechas nulas: 0\n",
      "  • Rango de fechas: 2025-01-01 00:00:00 a 2025-03-31 00:00:00\n",
      "\n",
      "Licitación:\n",
      "  • Registros: 247,354\n",
      "  • Columnas: 52\n",
      "  • Monto total: $4,068,295,809,810 CLP\n",
      "  • Monto promedio: $16,447,261 CLP\n",
      "  • Valores nulos en MontoTotalOC: 0\n",
      "  • Fechas nulas: 0\n",
      "  • Rango de fechas: 2025-01-01 00:00:00 a 2025-03-31 00:00:00\n",
      "\n",
      "Compra Ágil:\n",
      "  • Registros: 605,008\n",
      "  • Columnas: 69\n",
      "  • Monto total: $1,598,198,297,372 CLP\n",
      "  • Monto promedio: $2,641,615 CLP\n",
      "  • Valores nulos en MontoTotalOC: 0\n",
      "  • Fechas nulas: 0\n",
      "  • Rango de fechas: 2025-01-01 00:00:00 a 2025-03-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Función para limpiar y preparar los datos\n",
    "def limpiar_datos_salud(df, nombre_dataset):\n",
    "    \"\"\"\n",
    "    Limpia y prepara los datos de compras públicas del sector salud\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # 1. Agregar identificador de dataset\n",
    "    df_clean['Dataset'] = nombre_dataset\n",
    "    \n",
    "    # 2. Limpiar y convertir montos a numéricos\n",
    "    if 'MontoTotalOC' in df_clean.columns:\n",
    "        # Convertir a string y limpiar\n",
    "        df_clean['MontoTotalOC'] = df_clean['MontoTotalOC'].astype(str)\n",
    "        # Eliminar puntos de miles y reemplazar comas por puntos decimales\n",
    "        df_clean['MontoTotalOC'] = df_clean['MontoTotalOC'].str.replace('.', '', regex=False)\n",
    "        df_clean['MontoTotalOC'] = df_clean['MontoTotalOC'].str.replace(',', '.', regex=False)\n",
    "        # Convertir a numérico\n",
    "        df_clean['MontoTotalOC'] = pd.to_numeric(df_clean['MontoTotalOC'], errors='coerce')\n",
    "    \n",
    "    # 3. Limpiar otros campos de montos si existen\n",
    "    campos_montos = ['MontoNetoOC', 'MontoNetoItem', 'MontoTotalItem', 'MontoNetoItemCLP']\n",
    "    for campo in campos_montos:\n",
    "        if campo in df_clean.columns:\n",
    "            df_clean[campo] = df_clean[campo].astype(str)\n",
    "            df_clean[campo] = df_clean[campo].str.replace('.', '', regex=False)\n",
    "            df_clean[campo] = df_clean[campo].str.replace(',', '.', regex=False)\n",
    "            df_clean[campo] = pd.to_numeric(df_clean[campo], errors='coerce')\n",
    "    \n",
    "    # 4. Limpiar fechas\n",
    "    if 'FechaEnvioOC' in df_clean.columns:\n",
    "        df_clean['FechaEnvioOC'] = pd.to_datetime(df_clean['FechaEnvioOC'], errors='coerce', dayfirst=True)\n",
    "        df_clean['Año'] = df_clean['FechaEnvioOC'].dt.year\n",
    "        df_clean['Mes'] = df_clean['FechaEnvioOC'].dt.month\n",
    "        df_clean['Trimestre'] = df_clean['FechaEnvioOC'].dt.quarter\n",
    "        df_clean['DiaSemana'] = df_clean['FechaEnvioOC'].dt.dayofweek\n",
    "        df_clean['Semana'] = df_clean['FechaEnvioOC'].dt.isocalendar().week\n",
    "    \n",
    "    # 5. Limpiar campos de texto\n",
    "    campos_texto = ['Proveedor', 'Institucion', 'DescripcionOC', 'NombreOC']\n",
    "    for campo in campos_texto:\n",
    "        if campo in df_clean.columns:\n",
    "            df_clean[campo] = df_clean[campo].astype(str).str.strip()\n",
    "            df_clean[campo] = df_clean[campo].replace('nan', '')\n",
    "    \n",
    "    # 6. Standardizar códigos\n",
    "    if 'codigoOC' in df_clean.columns:\n",
    "        df_clean['codigoOC'] = df_clean['codigoOC'].astype(str).str.strip()\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Aplicar limpieza a todos los datasets\n",
    "print(\"Limpiando datos del sector salud...\")\n",
    "df_td_clean = limpiar_datos_salud(df_td, 'Trato Directo')\n",
    "df_cm_clean = limpiar_datos_salud(df_cm, 'Convenio Marco')\n",
    "df_lic_clean = limpiar_datos_salud(df_lic, 'Licitación')\n",
    "df_ca_clean = limpiar_datos_salud(df_ca, 'Compra Ágil')\n",
    "\n",
    "# Verificar resultados de la limpieza\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RESULTADOS DE LA LIMPIEZA\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "datasets = {\n",
    "    'Trato Directo': df_td_clean,\n",
    "    'Convenio Marco': df_cm_clean,\n",
    "    'Licitación': df_lic_clean,\n",
    "    'Compra Ágil': df_ca_clean\n",
    "}\n",
    "\n",
    "for nombre, df in datasets.items():\n",
    "    print(f\"\\n{nombre}:\")\n",
    "    print(f\"  • Registros: {len(df):,}\")\n",
    "    print(f\"  • Columnas: {len(df.columns)}\")\n",
    "    \n",
    "    if 'MontoTotalOC' in df.columns:\n",
    "        monto_total = df['MontoTotalOC'].sum()\n",
    "        monto_promedio = df['MontoTotalOC'].mean()\n",
    "        print(f\"  • Monto total: ${monto_total:,.0f} CLP\")\n",
    "        print(f\"  • Monto promedio: ${monto_promedio:,.0f} CLP\")\n",
    "        print(f\"  • Valores nulos en MontoTotalOC: {df['MontoTotalOC'].isnull().sum()}\")\n",
    "    \n",
    "    if 'FechaEnvioOC' in df.columns:\n",
    "        fechas_nulas = df['FechaEnvioOC'].isnull().sum()\n",
    "        print(f\"  • Fechas nulas: {fechas_nulas}\")\n",
    "        if fechas_nulas < len(df):\n",
    "            fecha_min = df['FechaEnvioOC'].min()\n",
    "            fecha_max = df['FechaEnvioOC'].max()\n",
    "            print(f\"  • Rango de fechas: {fecha_min} a {fecha_max}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ef08924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EXPLORACIÓN DE COLUMNAS POR DATASET\n",
      "======================================================================\n",
      "\n",
      "TRATO DIRECTO:\n",
      "Total de columnas: 50\n",
      "--------------------------------------------------\n",
      " 1. codigoOC\n",
      " 2. FechaEnvioOC\n",
      " 3. NombreOC\n",
      " 4. DescripcionOC\n",
      " 5. EstadoOC\n",
      " 6. ProcedenciaOC\n",
      " 7. MonedaOC\n",
      " 8. MontoNetoOC\n",
      " 9. DescuentosOC\n",
      "10. CargosOC\n",
      "11. ImpuestosOC\n",
      "12. MontoTotalOC\n",
      "13. ImpuestosOC_CLP\n",
      "14. MontoNetoOC_CLP\n",
      "15. MetodoPago\n",
      "16. TipoDespacho\n",
      "17. Financiamiento\n",
      "18. UnidadCompra\n",
      "19. UnidadCompraRUT\n",
      "20. RegionUnidadCompra\n",
      "21. entCode\n",
      "22. Institucion\n",
      "23. Sector\n",
      "24. Proveedor\n",
      "25. ProveedorRUT\n",
      "26. ActividadProveedor\n",
      "27. TamanoProveedor\n",
      "28. RegionProveedor\n",
      "29. RubroN1\n",
      "30. RubroN2\n",
      "31. RubroN3\n",
      "32. CodigoProductoONU\n",
      "33. ONUProducto\n",
      "34. NombreItem\n",
      "35. DescripcionItem\n",
      "36. CantidadItem\n",
      "37. UnidadMedida\n",
      "38. MonedaItem\n",
      "39. MontoNetoItem\n",
      "40. DescuentoItem\n",
      "41. CargosItem\n",
      "42. ImpuestoEspecificoItem\n",
      "43. MontoTotalItem\n",
      "44. MontoNetoItemCLP\n",
      "45. Dataset\n",
      "46. Año\n",
      "47. Mes\n",
      "48. Trimestre\n",
      "49. DiaSemana\n",
      "50. Semana\n",
      "\n",
      "CONVENIO MARCO:\n",
      "Total de columnas: 65\n",
      "--------------------------------------------------\n",
      " 1. codigoOC\n",
      " 2. NroConvenioMarco\n",
      " 3. FechaEnvioOC\n",
      " 4. NombreOC\n",
      " 5. DescripcionOC\n",
      " 6. EstadoOC\n",
      " 7. ProcedenciaOC\n",
      " 8. CompraCoordinada\n",
      " 9. GranCompra\n",
      "10. idGranCompra\n",
      "11. NombreGranCompra\n",
      "12. FechaDesde_PeriodoInvitacion\n",
      "13. FechaHasta_PeriodoInvitacion\n",
      "14. MontoAprobGC_SubTotal\n",
      "15. MontoAprobGC_SubTotalIVA\n",
      "16. MontoAprobGC_ImpEsp\n",
      "17. MontoAprobGC_TotalFinal\n",
      "18. GlosaEvaluacion\n",
      "19. MonedaOC\n",
      "20. MontoNetoOC\n",
      "21. DescuentosOC\n",
      "22. CargosOC\n",
      "23. ImpuestosOC\n",
      "24. MontoTotalOC\n",
      "25. ImpuestosOC_CLP\n",
      "26. MontoNetoOC_CLP\n",
      "27. MetodoPago\n",
      "28. TipoDespacho\n",
      "29. Financiamiento\n",
      "30. UnidadCompra\n",
      "31. UnidadCompraRUT\n",
      "32. RegionUnidadCompra\n",
      "33. entCode\n",
      "34. Institucion\n",
      "35. Sector\n",
      "36. Proveedor\n",
      "37. ProveedorRUT\n",
      "38. ActividadProveedor\n",
      "39. TamanoProveedor\n",
      "40. RegionProveedor\n",
      "41. RubroN1\n",
      "42. RubroN2\n",
      "43. RubroN3\n",
      "44. CodigoProductoONU\n",
      "45. ONUProducto\n",
      "46. Producto\n",
      "47. Modelo\n",
      "48. Marca\n",
      "49. NombreItem\n",
      "50. DescripcionItem\n",
      "51. CantidadItem\n",
      "52. UnidadMedida\n",
      "53. MonedaItem\n",
      "54. MontoNetoItem\n",
      "55. DescuentoItem\n",
      "56. CargosItem\n",
      "57. ImpuestoEspecificoItem\n",
      "58. MontoTotalItem\n",
      "59. MontoNetoItemCLP\n",
      "60. Dataset\n",
      "61. Año\n",
      "62. Mes\n",
      "63. Trimestre\n",
      "64. DiaSemana\n",
      "65. Semana\n",
      "\n",
      "LICITACIÓN:\n",
      "Total de columnas: 52\n",
      "--------------------------------------------------\n",
      " 1. codigoOC\n",
      " 2. NroLicitacion\n",
      " 3. FechaEnvioOC\n",
      " 4. NombreOC\n",
      " 5. DescripcionOC\n",
      " 6. EstadoOC\n",
      " 7. ProcedenciaOC\n",
      " 8. CompraCoordinada\n",
      " 9. MonedaOC\n",
      "10. MontoNetoOC\n",
      "11. DescuentosOC\n",
      "12. CargosOC\n",
      "13. ImpuestosOC\n",
      "14. MontoTotalOC\n",
      "15. ImpuestosOC_CLP\n",
      "16. MontoNetoOC_CLP\n",
      "17. MetodoPago\n",
      "18. TipoDespacho\n",
      "19. Financiamiento\n",
      "20. UnidadCompra\n",
      "21. UnidadCompraRUT\n",
      "22. RegionUnidadCompra\n",
      "23. entCode\n",
      "24. Institucion\n",
      "25. Sector\n",
      "26. Proveedor\n",
      "27. ProveedorRUT\n",
      "28. ActividadProveedor\n",
      "29. TamanoProveedor\n",
      "30. RegionProveedor\n",
      "31. RubroN1\n",
      "32. RubroN2\n",
      "33. RubroN3\n",
      "34. CodigoProductoONU\n",
      "35. ONUProducto\n",
      "36. NombreItem\n",
      "37. DescripcionItem\n",
      "38. CantidadItem\n",
      "39. UnidadMedida\n",
      "40. MonedaItem\n",
      "41. MontoNetoItem\n",
      "42. DescuentoItem\n",
      "43. CargosItem\n",
      "44. ImpuestoEspecificoItem\n",
      "45. MontoTotalItem\n",
      "46. MontoNetoItemCLP\n",
      "47. Dataset\n",
      "48. Año\n",
      "49. Mes\n",
      "50. Trimestre\n",
      "51. DiaSemana\n",
      "52. Semana\n",
      "\n",
      "COMPRA ÁGIL:\n",
      "Total de columnas: 69\n",
      "--------------------------------------------------\n",
      " 1. codigoOC\n",
      " 2. FechaEnvioOC\n",
      " 3. NombreOC\n",
      " 4. DescripcionOC\n",
      " 5. EstadoOC\n",
      " 6. ProcedenciaOC\n",
      " 7. MonedaOC\n",
      " 8. MontoNetoOC\n",
      " 9. DescuentosOC\n",
      "10. CargosOC\n",
      "11. ImpuestosOC\n",
      "12. MontoTotalOC\n",
      "13. ImpuestosOC_CLP\n",
      "14. MontoNetoOC_CLP\n",
      "15. MetodoPago\n",
      "16. TipoDespacho\n",
      "17. Financiamiento\n",
      "18. UnidadCompra\n",
      "19. UnidadCompraRUT\n",
      "20. RegionUnidadCompra\n",
      "21. entCode\n",
      "22. Institucion\n",
      "23. Sector\n",
      "24. Proveedor\n",
      "25. ProveedorRUT\n",
      "26. ActividadProveedor\n",
      "27. TamanoProveedor\n",
      "28. RegionProveedor\n",
      "29. RubroN1\n",
      "30. RubroN2\n",
      "31. RubroN3\n",
      "32. CodigoProductoONU\n",
      "33. ONUProducto\n",
      "34. NombreItem\n",
      "35. DescripcionItem\n",
      "36. CantidadItem\n",
      "37. UnidadMedida\n",
      "38. MonedaItem\n",
      "39. MontoNetoItem\n",
      "40. DescuentoItem\n",
      "41. CargosItem\n",
      "42. ImpuestoEspecificoItem\n",
      "43. MontoTotalItem\n",
      "44. MontoNetoItemCLP\n",
      "45. CodigoCotizacion\n",
      "46. NombreCotizacion\n",
      "47. DescripcionCotizacion\n",
      "48. FechaPublicacionCotizacion\n",
      "49. FechaCierreCotizacion\n",
      "50. MontoDisponible\n",
      "51. DescripcionProducto\n",
      "52. CodigoProductoCotizadoONU\n",
      "53. ProductoCotizado\n",
      "54. CantidadSolicitada\n",
      "55. ProveedorCotizacion\n",
      "56. RUTProveedorCotizacion\n",
      "57. DetalleCotizacion\n",
      "58. PrecioUnitarioCotizacion\n",
      "59. PrecioTotalItemCotizacion\n",
      "60. MontoNetoCotizacion\n",
      "61. MontoDespachoCotizacion\n",
      "62. MontoTotalCotizacion\n",
      "63. ProveedorSeleccionado\n",
      "64. Dataset\n",
      "65. Año\n",
      "66. Mes\n",
      "67. Trimestre\n",
      "68. DiaSemana\n",
      "69. Semana\n",
      "\n",
      "======================================================================\n",
      "ANÁLISIS DE COLUMNAS COMUNES Y ÚNICAS\n",
      "======================================================================\n",
      "\n",
      "Columnas comunes a TODOS los datasets (50):\n",
      " 1. ActividadProveedor\n",
      " 2. Año\n",
      " 3. CantidadItem\n",
      " 4. CargosItem\n",
      " 5. CargosOC\n",
      " 6. CodigoProductoONU\n",
      " 7. Dataset\n",
      " 8. DescripcionItem\n",
      " 9. DescripcionOC\n",
      "10. DescuentoItem\n",
      "11. DescuentosOC\n",
      "12. DiaSemana\n",
      "13. EstadoOC\n",
      "14. FechaEnvioOC\n",
      "15. Financiamiento\n",
      "16. ImpuestoEspecificoItem\n",
      "17. ImpuestosOC\n",
      "18. ImpuestosOC_CLP\n",
      "19. Institucion\n",
      "20. Mes\n",
      "21. MetodoPago\n",
      "22. MonedaItem\n",
      "23. MonedaOC\n",
      "24. MontoNetoItem\n",
      "25. MontoNetoItemCLP\n",
      "26. MontoNetoOC\n",
      "27. MontoNetoOC_CLP\n",
      "28. MontoTotalItem\n",
      "29. MontoTotalOC\n",
      "30. NombreItem\n",
      "31. NombreOC\n",
      "32. ONUProducto\n",
      "33. ProcedenciaOC\n",
      "34. Proveedor\n",
      "35. ProveedorRUT\n",
      "36. RegionProveedor\n",
      "37. RegionUnidadCompra\n",
      "38. RubroN1\n",
      "39. RubroN2\n",
      "40. RubroN3\n",
      "41. Sector\n",
      "42. Semana\n",
      "43. TamanoProveedor\n",
      "44. TipoDespacho\n",
      "45. Trimestre\n",
      "46. UnidadCompra\n",
      "47. UnidadCompraRUT\n",
      "48. UnidadMedida\n",
      "49. codigoOC\n",
      "50. entCode\n",
      "\n",
      "Columnas ÚNICAS por dataset:\n",
      "\n",
      "Trato Directo: No tiene columnas únicas\n",
      "\n",
      "Convenio Marco (15 únicas):\n",
      "   1. CompraCoordinada\n",
      "   2. FechaDesde_PeriodoInvitacion\n",
      "   3. FechaHasta_PeriodoInvitacion\n",
      "   4. GlosaEvaluacion\n",
      "   5. GranCompra\n",
      "   6. Marca\n",
      "   7. Modelo\n",
      "   8. MontoAprobGC_ImpEsp\n",
      "   9. MontoAprobGC_SubTotal\n",
      "  10. MontoAprobGC_SubTotalIVA\n",
      "  11. MontoAprobGC_TotalFinal\n",
      "  12. NombreGranCompra\n",
      "  13. NroConvenioMarco\n",
      "  14. Producto\n",
      "  15. idGranCompra\n",
      "\n",
      "Licitación (2 únicas):\n",
      "   1. CompraCoordinada\n",
      "   2. NroLicitacion\n",
      "\n",
      "Compra Ágil (19 únicas):\n",
      "   1. CantidadSolicitada\n",
      "   2. CodigoCotizacion\n",
      "   3. CodigoProductoCotizadoONU\n",
      "   4. DescripcionCotizacion\n",
      "   5. DescripcionProducto\n",
      "   6. DetalleCotizacion\n",
      "   7. FechaCierreCotizacion\n",
      "   8. FechaPublicacionCotizacion\n",
      "   9. MontoDespachoCotizacion\n",
      "  10. MontoDisponible\n",
      "  11. MontoNetoCotizacion\n",
      "  12. MontoTotalCotizacion\n",
      "  13. NombreCotizacion\n",
      "  14. PrecioTotalItemCotizacion\n",
      "  15. PrecioUnitarioCotizacion\n",
      "  16. ProductoCotizado\n",
      "  17. ProveedorCotizacion\n",
      "  18. ProveedorSeleccionado\n",
      "  19. RUTProveedorCotizacion\n"
     ]
    }
   ],
   "source": [
    "# Explorar todas las columnas de cada dataset\n",
    "print(\"=\"*70)\n",
    "print(\"EXPLORACIÓN DE COLUMNAS POR DATASET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "datasets = {\n",
    "    'Trato Directo': df_td_clean,\n",
    "    'Convenio Marco': df_cm_clean,\n",
    "    'Licitación': df_lic_clean,\n",
    "    'Compra Ágil': df_ca_clean\n",
    "}\n",
    "\n",
    "# Mostrar columnas de cada dataset\n",
    "for nombre, df in datasets.items():\n",
    "    print(f\"\\n{nombre.upper()}:\")\n",
    "    print(f\"Total de columnas: {len(df.columns)}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Mostrar columnas numeradas para facilitar referencia\n",
    "    for i, col in enumerate(df.columns, 1):\n",
    "        print(f\"{i:2d}. {col}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ANÁLISIS DE COLUMNAS COMUNES Y ÚNICAS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Encontrar columnas comunes a todos los datasets\n",
    "columnas_todas = [set(df.columns) for df in datasets.values()]\n",
    "columnas_comunes = set.intersection(*columnas_todas)\n",
    "\n",
    "print(f\"\\nColumnas comunes a TODOS los datasets ({len(columnas_comunes)}):\")\n",
    "for i, col in enumerate(sorted(columnas_comunes), 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "# Encontrar columnas únicas por dataset\n",
    "print(f\"\\nColumnas ÚNICAS por dataset:\")\n",
    "for nombre, df in datasets.items():\n",
    "    columnas_unicas = set(df.columns) - columnas_comunes\n",
    "    if columnas_unicas:\n",
    "        print(f\"\\n{nombre} ({len(columnas_unicas)} únicas):\")\n",
    "        for i, col in enumerate(sorted(columnas_unicas), 1):\n",
    "            print(f\"  {i:2d}. {col}\")\n",
    "    else:\n",
    "        print(f\"\\n{nombre}: No tiene columnas únicas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "513655ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FILTRANDO Y GUARDANDO DATASETS\n",
      "======================================================================\n",
      "\n",
      "TRATO DIRECTO:\n",
      "  • Columnas solicitadas: 29\n",
      "  • Columnas disponibles: 29\n",
      "  • Columnas faltantes: 0\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'datos_limpios/salud'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 117\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m70\u001b[39m)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Filtrar y guardar cada dataset\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m df_td_filtrado \u001b[38;5;241m=\u001b[39m filtrar_y_guardar(\n\u001b[1;32m    118\u001b[0m     df_td_clean, \n\u001b[1;32m    119\u001b[0m     columnas_trato_directo, \n\u001b[1;32m    120\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrato_directo_filtrado.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m    121\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrato Directo\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    122\u001b[0m )\n\u001b[1;32m    124\u001b[0m df_cm_filtrado \u001b[38;5;241m=\u001b[39m filtrar_y_guardar(\n\u001b[1;32m    125\u001b[0m     df_cm_clean, \n\u001b[1;32m    126\u001b[0m     columnas_convenio_marco, \n\u001b[1;32m    127\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconvenio_marco_filtrado.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m    128\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConvenio Marco\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    129\u001b[0m )\n\u001b[1;32m    131\u001b[0m df_lic_filtrado \u001b[38;5;241m=\u001b[39m filtrar_y_guardar(\n\u001b[1;32m    132\u001b[0m     df_lic_clean, \n\u001b[1;32m    133\u001b[0m     columnas_licitacion, \n\u001b[1;32m    134\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlicitacion_filtrado.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m    135\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLicitación\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    136\u001b[0m )\n",
      "Cell \u001b[0;32mIn[6], line 104\u001b[0m, in \u001b[0;36mfiltrar_y_guardar\u001b[0;34m(df, columnas_deseadas, nombre_archivo, nombre_modalidad)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# Guardar el dataset filtrado\u001b[39;00m\n\u001b[1;32m    103\u001b[0m ruta_archivo \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatos_limpios/salud/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnombre_archivo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 104\u001b[0m df_filtrado\u001b[38;5;241m.\u001b[39mto_csv(ruta_archivo, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  • Dataset guardado en: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mruta_archivo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  • Registros: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_filtrado)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ast/lib/python3.13/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ast/lib/python3.13/site-packages/pandas/core/generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3965\u001b[0m )\n\u001b[0;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[1;32m   3968\u001b[0m     path_or_buf,\n\u001b[1;32m   3969\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   3970\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[1;32m   3971\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m   3972\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m   3973\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[1;32m   3974\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[1;32m   3975\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   3976\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[1;32m   3977\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m   3978\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m   3979\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[1;32m   3980\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[1;32m   3981\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[1;32m   3982\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[1;32m   3983\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m   3984\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ast/lib/python3.13/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ast/lib/python3.13/site-packages/pandas/io/formats/csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    254\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    255\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,\n\u001b[1;32m    256\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[1;32m    257\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[1;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ast/lib/python3.13/site-packages/pandas/io/common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 749\u001b[0m     check_parent_directory(\u001b[38;5;28mstr\u001b[39m(handle))\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ast/lib/python3.13/site-packages/pandas/io/common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'datos_limpios/salud'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "os.makedirs('../datos_limpios/salud', exist_ok=True)\n",
    "\n",
    "# Definir las columnas para cada dataset\n",
    "columnas_trato_directo = [\n",
    "    # Identidad institucional\n",
    "    'Institucion', 'UnidadCompra', 'RegionUnidadCompra',\n",
    "    # Identidad proveedor\n",
    "    'Proveedor', 'ProveedorRUT', 'TamanoProveedor', 'ActividadProveedor', 'RegionProveedor',\n",
    "    # Monto\n",
    "    'MontoTotalOC', 'MontoNetoOC_CLP', 'ImpuestosOC_CLP', 'DescuentosOC', 'CargosOC',\n",
    "    # Producto o servicio\n",
    "    'NombreItem', 'DescripcionItem', 'CantidadItem', 'UnidadMedida', 'MontoNetoItemCLP', 'CodigoProductoONU', 'ONUProducto',\n",
    "    # Condiciones de pago\n",
    "    'MetodoPago', 'TipoDespacho',\n",
    "    # Tiempo\n",
    "    'FechaEnvioOC', 'Año', 'Mes', 'Trimestre',\n",
    "    # Clasificación del gasto\n",
    "    'RubroN1', 'RubroN2',\n",
    "    # Control de duplicados\n",
    "    'codigoOC'\n",
    "]\n",
    "\n",
    "columnas_convenio_marco = [\n",
    "    # Identidad institucional\n",
    "    'Institucion', 'UnidadCompra', 'RegionUnidadCompra', 'Sector',\n",
    "    # Identidad proveedor\n",
    "    'Proveedor', 'ProveedorRUT', 'TamanoProveedor', 'ActividadProveedor', 'RegionProveedor',\n",
    "    # Montos\n",
    "    'MontoTotalOC', 'MontoNetoOC_CLP', 'ImpuestosOC_CLP', 'DescuentosOC', 'CargosOC',\n",
    "    # Producto técnico\n",
    "    'NombreItem', 'DescripcionItem', 'CantidadItem', 'MontoNetoItemCLP', 'CodigoProductoONU', 'ONUProducto', 'Producto', 'Modelo', 'Marca',\n",
    "    # Condiciones\n",
    "    'MetodoPago', 'CompraCoordinada', 'GranCompra', 'MontoAprobGC_TotalFinal',\n",
    "    # Tiempo\n",
    "    'FechaEnvioOC', 'Año', 'Mes', 'Trimestre',\n",
    "    # Clasificación del gasto\n",
    "    'RubroN1', 'RubroN2',\n",
    "    # Evaluación\n",
    "    'GlosaEvaluacion',\n",
    "    # Control y trazabilidad\n",
    "    'codigoOC', 'NroConvenioMarco'\n",
    "]\n",
    "\n",
    "columnas_licitacion = [\n",
    "    # Identidad institucional\n",
    "    'Institucion', 'UnidadCompra', 'RegionUnidadCompra', 'Sector',\n",
    "    # Proveedor\n",
    "    'Proveedor', 'ProveedorRUT', 'TamanoProveedor', 'ActividadProveedor', 'RegionProveedor',\n",
    "    # Montos\n",
    "    'MontoTotalOC', 'MontoNetoOC_CLP', 'ImpuestosOC_CLP', 'DescuentosOC', 'CargosOC',\n",
    "    # Detalle producto/servicio\n",
    "    'NombreItem', 'DescripcionItem', 'CantidadItem', 'MontoNetoItemCLP', 'CodigoProductoONU', 'ONUProducto',\n",
    "    # Condiciones de compra\n",
    "    'MetodoPago', 'CompraCoordinada', 'NroLicitacion',\n",
    "    # Tiempo\n",
    "    'FechaEnvioOC', 'Año', 'Mes', 'Trimestre',\n",
    "    # Clasificación del gasto\n",
    "    'RubroN1', 'RubroN2',\n",
    "    # Trazabilidad\n",
    "    'codigoOC'\n",
    "]\n",
    "\n",
    "columnas_compra_agil = [\n",
    "    # Identidad institucional\n",
    "    'Institucion', 'UnidadCompra', 'RegionUnidadCompra',\n",
    "    # Proveedor y adjudicación\n",
    "    'Proveedor', 'ProveedorRUT', 'TamanoProveedor', 'ProveedorCotizacion', 'ProveedorSeleccionado',\n",
    "    # Montos OC y cotización\n",
    "    'MontoTotalOC', 'MontoNetoOC_CLP', 'MontoNetoCotizacion', 'MontoTotalCotizacion', 'MontoDisponible', 'PrecioUnitarioCotizacion',\n",
    "    # Detalle del producto\n",
    "    'NombreItem', 'DescripcionItem', 'CantidadItem', 'MontoNetoItemCLP', 'ProductoCotizado', 'CantidadSolicitada', 'CodigoProductoONU',\n",
    "    # Condiciones de compra\n",
    "    'MetodoPago', 'CodigoCotizacion', 'DescripcionCotizacion',\n",
    "    # Fechas y tiempo\n",
    "    'FechaEnvioOC', 'FechaPublicacionCotizacion', 'FechaCierreCotizacion', 'Mes', 'Trimestre',\n",
    "    # Clasificación del gasto\n",
    "    'RubroN1', 'RubroN2',\n",
    "    # Control / trazabilidad\n",
    "    'codigoOC'\n",
    "]\n",
    "\n",
    "# Función para filtrar y guardar datasets\n",
    "def filtrar_y_guardar(df, columnas_deseadas, nombre_archivo, nombre_modalidad):\n",
    "    \"\"\"\n",
    "    Filtra el dataset con las columnas especificadas y lo guarda\n",
    "    \"\"\"\n",
    "    # Identificar qué columnas están disponibles\n",
    "    columnas_disponibles = [col for col in columnas_deseadas if col in df.columns]\n",
    "    columnas_faltantes = [col for col in columnas_deseadas if col not in df.columns]\n",
    "    \n",
    "    print(f\"\\n{nombre_modalidad.upper()}:\")\n",
    "    print(f\"  • Columnas solicitadas: {len(columnas_deseadas)}\")\n",
    "    print(f\"  • Columnas disponibles: {len(columnas_disponibles)}\")\n",
    "    print(f\"  • Columnas faltantes: {len(columnas_faltantes)}\")\n",
    "    \n",
    "    if columnas_faltantes:\n",
    "        print(f\"  • Columnas NO encontradas: {columnas_faltantes}\")\n",
    "    \n",
    "    # Filtrar el dataset\n",
    "    df_filtrado = df[columnas_disponibles].copy()\n",
    "    \n",
    "    # Guardar el dataset filtrado\n",
    "    ruta_archivo = f'datos_limpios/salud/{nombre_archivo}'\n",
    "    df_filtrado.to_csv(ruta_archivo, index=False, sep=';', encoding='utf-8')\n",
    "    \n",
    "    print(f\"  • Dataset guardado en: {ruta_archivo}\")\n",
    "    print(f\"  • Registros: {len(df_filtrado):,}\")\n",
    "    print(f\"  • Columnas finales: {len(df_filtrado.columns)}\")\n",
    "    \n",
    "    return df_filtrado\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FILTRANDO Y GUARDANDO DATASETS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Filtrar y guardar cada dataset\n",
    "df_td_filtrado = filtrar_y_guardar(\n",
    "    df_td_clean, \n",
    "    columnas_trato_directo, \n",
    "    'trato_directo_filtrado.csv', \n",
    "    'Trato Directo'\n",
    ")\n",
    "\n",
    "df_cm_filtrado = filtrar_y_guardar(\n",
    "    df_cm_clean, \n",
    "    columnas_convenio_marco, \n",
    "    'convenio_marco_filtrado.csv', \n",
    "    'Convenio Marco'\n",
    ")\n",
    "\n",
    "df_lic_filtrado = filtrar_y_guardar(\n",
    "    df_lic_clean, \n",
    "    columnas_licitacion, \n",
    "    'licitacion_filtrado.csv', \n",
    "    'Licitación'\n",
    ")\n",
    "\n",
    "df_ca_filtrado = filtrar_y_guardar(\n",
    "    df_ca_clean, \n",
    "    columnas_compra_agil, \n",
    "    'compra_agil_filtrado.csv', \n",
    "    'Compra Ágil'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESUMEN DE ARCHIVOS GUARDADOS\")\n",
    "print(\"=\"*70)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
